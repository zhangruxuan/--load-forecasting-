{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd  \n",
    "from tensorflow.keras.models import Sequential\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow.keras.backend as K\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# #这一块是用来指定用于训练GPU以及设定显存按需分配\n",
    "# ### 使得这里的编号和nvidia-smi看到的编号是一样的\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "# ### 指定只能看到编号为3的GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "# ### 设定显存按需分配\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True   \n",
    "# session = tf.compat.v1.Session(config=config)\n",
    "# tf.compat.v1.keras.backend.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# data_file_path = r'C:\\Users\\93710\\Desktop\\model\\dataset\\apart1-weather(1).csv'\n",
    "# data_csv = pd.read_csv(data_file_path)\n",
    "import pickle\n",
    "#加载pickle\n",
    "pkl_file = open('../Untitled Folder/data1.pkl', 'rb')\n",
    "data1 = pickle.load(pkl_file)\n",
    "name = list(data1.keys())\n",
    "# for i in range(len(name)):\n",
    "#     time = data1[name[i]][0]\n",
    "#     value = data1[name[i]][1]\n",
    "#     print(time,value)\n",
    "\n",
    "value = data1[name[0]][1]\n",
    "value = [float(x) for x in value]\n",
    "data_label = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# data_file_path = r\"C:\\Users\\zrx\\Desktop\\Electric_load_forecasting-master\\Untitled Folder\\imf.csv\"\n",
    "# data_csv = pd.read_csv(data_file_path)\n",
    "# data_use_0 = data_csv['0']\n",
    "data_use_0 = value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据分组处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_use_train_0 = []\n",
    "\n",
    "label_train = []\n",
    "\n",
    "num_start = 0\n",
    "num_end = num_start+168\n",
    "label_start = num_end\n",
    "label_end = label_start+24\n",
    "while label_end<len(data_use_0):\n",
    "    data_use_train_0.append(data_use_0[num_start:num_end])\n",
    "    label_train.append(data_label[label_start:label_end])\n",
    "    num_start += 24\n",
    "    num_end = num_start+168\n",
    "    label_start = num_end\n",
    "    label_end = label_start+24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_use_train_0 = np.array(data_use_train_0)\n",
    "\n",
    "label_train = np.array(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_num = int(0.9*len(data_use_train_0))\n",
    "train_data_use_0 = data_use_train_0[:train_num]\n",
    "\n",
    "train_label = label_train[:train_num]\n",
    "\n",
    "test_data_use_0 = data_use_train_0[train_num:]\n",
    "\n",
    "test_label = label_train[train_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data_use_0 = train_data_use_0.reshape(train_data_use_0.shape[0],7,24)\n",
    "\n",
    "\n",
    "test_data_use_0 = test_data_use_0.reshape(test_data_use_0.shape[0],7,24)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 24)\n"
     ]
    }
   ],
   "source": [
    "#设定model名称\n",
    "model_name = 'ykc_Bilstm'\n",
    "data_shape_use = train_data_use_0[0].shape\n",
    "print(data_shape_use)\n",
    "#data_shape_other = test_other_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def self_attention(x):\n",
    "    m = dot([x, x], axes=[2,2])\n",
    "    n = Activation('softmax')(m)\n",
    "    o = dot([n, x], axes=[2,1])\n",
    "    a = multiply([o, x])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (bidirectional_2/forward_lstm_2/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-36-f0218280e08a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[0mx_flatten_0\u001B[0m  \u001B[1;33m=\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[0mx_input_use_0\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata_shape_use\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[0mx_flatten_0\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBidirectional\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mLSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m24\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.5\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mreturn_sequences\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_input_use_0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;31m# x_flatten_0 = self_attention(x_flatten_0)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[0mx_flatten_0\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFlatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_flatten_0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs, initial_state, constants, **kwargs)\u001B[0m\n\u001B[0;32m    537\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    538\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0minitial_state\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mconstants\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 539\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBidirectional\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    540\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    541\u001B[0m     \u001B[1;31m# Applies the same workaround as in `RNN.__call__`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    949\u001B[0m     \u001B[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    950\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_in_functional_construction_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 951\u001B[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001B[0m\u001B[0;32m    952\u001B[0m                                                 input_list)\n\u001B[0;32m    953\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m_functional_construction_call\u001B[1;34m(self, inputs, args, kwargs, input_list)\u001B[0m\n\u001B[0;32m   1088\u001B[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001B[0;32m   1089\u001B[0m         \u001B[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1090\u001B[1;33m         outputs = self._keras_tensor_symbolic_call(\n\u001B[0m\u001B[0;32m   1091\u001B[0m             inputs, input_masks, args, kwargs)\n\u001B[0;32m   1092\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m_keras_tensor_symbolic_call\u001B[1;34m(self, inputs, input_masks, args, kwargs)\u001B[0m\n\u001B[0;32m    820\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkeras_tensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mKerasTensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_signature\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    821\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 822\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_infer_output_signature\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    823\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    824\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_infer_output_signature\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m_infer_output_signature\u001B[1;34m(self, inputs, args, kwargs, input_masks)\u001B[0m\n\u001B[0;32m    861\u001B[0m           \u001B[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    862\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_build\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 863\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    864\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    865\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, training, mask, initial_state, constants)\u001B[0m\n\u001B[0;32m    650\u001B[0m         \u001B[0mforward_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbackward_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    651\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 652\u001B[1;33m       y = self.forward_layer(forward_inputs,\n\u001B[0m\u001B[0;32m    653\u001B[0m                              initial_state=forward_state, **kwargs)\n\u001B[0;32m    654\u001B[0m       y_rev = self.backward_layer(backward_inputs,\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs, initial_state, constants, **kwargs)\u001B[0m\n\u001B[0;32m    658\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    659\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0minitial_state\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mconstants\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 660\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mRNN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    661\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    662\u001B[0m     \u001B[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1010\u001B[0m         with autocast_variable.enable_auto_cast_variables(\n\u001B[0;32m   1011\u001B[0m             self._compute_dtype_object):\n\u001B[1;32m-> 1012\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1013\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1014\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, mask, training, initial_state)\u001B[0m\n\u001B[0;32m   1155\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1156\u001B[0m     \u001B[1;31m# LSTM does not support constants. Ignore it during process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1157\u001B[1;33m     \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_process_inputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1159\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m_process_inputs\u001B[1;34m(self, inputs, initial_state, constants)\u001B[0m\n\u001B[0;32m    857\u001B[0m         \u001B[0minitial_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    858\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0minitial_state\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 859\u001B[1;33m       \u001B[0minitial_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_initial_state\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    860\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    861\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minitial_state\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36mget_initial_state\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m    640\u001B[0m     \u001B[0mdtype\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    641\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mget_initial_state_fn\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 642\u001B[1;33m       init_state = get_initial_state_fn(\n\u001B[0m\u001B[0;32m    643\u001B[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001B[0;32m    644\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36mget_initial_state\u001B[1;34m(self, inputs, batch_size, dtype)\u001B[0m\n\u001B[0;32m   2504\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2505\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mget_initial_state\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2506\u001B[1;33m     return list(_generate_zero_filled_state_for_cell(\n\u001B[0m\u001B[0;32m   2507\u001B[0m         self, inputs, batch_size, dtype))\n\u001B[0;32m   2508\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m_generate_zero_filled_state_for_cell\u001B[1;34m(cell, inputs, batch_size, dtype)\u001B[0m\n\u001B[0;32m   2985\u001B[0m     \u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2986\u001B[0m     \u001B[0mdtype\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2987\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0m_generate_zero_filled_state\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2988\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2989\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m_generate_zero_filled_state\u001B[1;34m(batch_size_tensor, state_size, dtype)\u001B[0m\n\u001B[0;32m   3001\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3002\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_nested\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3003\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcreate_zeros\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstate_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3004\u001B[0m   \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3005\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mcreate_zeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    661\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    661\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36mcreate_zeros\u001B[1;34m(unnested_state_size)\u001B[0m\n\u001B[0;32m   2998\u001B[0m     \u001B[0mflat_dims\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtensor_shape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensorShape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munnested_state_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2999\u001B[0m     \u001B[0minit_state_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mbatch_size_tensor\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mflat_dims\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3000\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minit_state_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3001\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3002\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_nested\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36mwrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   2817\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2818\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2819\u001B[1;33m     \u001B[0mtensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2820\u001B[0m     \u001B[0mtensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_is_zeros_tensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2821\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36mzeros\u001B[1;34m(shape, dtype, name)\u001B[0m\n\u001B[0;32m   2866\u001B[0m           \u001B[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2867\u001B[0m           \u001B[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2868\u001B[1;33m           \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_constant_if_small\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzero\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2869\u001B[0m           \u001B[1;32mif\u001B[0m \u001B[0moutput\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2870\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0moutput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36m_constant_if_small\u001B[1;34m(value, shape, dtype, name)\u001B[0m\n\u001B[0;32m   2802\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_constant_if_small\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2803\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2804\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1000\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2805\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mconstant\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2806\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mprod\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36mprod\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m   3049\u001B[0m     \u001B[1;33m...\u001B[0m               \u001B[1;31m# total product 1*2*3 = 6\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3050\u001B[0m     \u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m6\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3051\u001B[1;33m     \u001B[1;33m>>\u001B[0m\u001B[1;33m>\u001B[0m \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m6\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3052\u001B[0m     \u001B[1;33m>>\u001B[0m\u001B[1;33m>\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcumprod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# specify type of output\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3053\u001B[0m     \u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m   \u001B[1;36m1.\u001B[0m\u001B[1;33m,\u001B[0m    \u001B[1;36m2.\u001B[0m\u001B[1;33m,\u001B[0m    \u001B[1;36m6.\u001B[0m\u001B[1;33m,\u001B[0m   \u001B[1;36m24.\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;36m120.\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;36m720.\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36m_wrapreduction\u001B[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpasskwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 86\u001B[1;33m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     87\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mufunc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduce\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpasskwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m__array__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    850\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    851\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 852\u001B[1;33m     raise NotImplementedError(\n\u001B[0m\u001B[0;32m    853\u001B[0m         \u001B[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    854\u001B[0m         \u001B[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: Cannot convert a symbolic Tensor (bidirectional_2/forward_lstm_2/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(1, batch_input_shape=(1, train_x.shape[1], train_x.shape[2]), stateful=True))\n",
    "# # model.add(LSTM(1, stateful=True, return_sequences=True))\n",
    "# # model.add(LSTM(1, stateful=True))\n",
    "# # model.add(Dense(train_y.shape[1]))\n",
    "# model.add(Dense(train_y.shape[1]))\n",
    "# model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "#构建最简单的LSTM\n",
    "# def build_lstm(n_in: int, n_features: int):\n",
    "#\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(12, activation='relu', input_shape=(n_in, n_features)))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(n_out))\n",
    "#     model.compile(optimizer='adam', loss='mae')\n",
    "#\n",
    "#     return model\n",
    "\n",
    "x_flatten_0  = Sequential()\n",
    "x_input_use_0 = Input(shape=data_shape_use)\n",
    "x_flatten_0 = Bidirectional(LSTM(24,dropout=0.5,return_sequences=True))(x_input_use_0)\n",
    "# x_flatten_0 = self_attention(x_flatten_0)\n",
    "x_flatten_0 = Flatten()(x_flatten_0)\n",
    "fusion_dense_0 = Dense(100)(x_flatten_0)\n",
    "fusion_dense_0 = Dropout(0.7)(fusion_dense_0)\n",
    "y_0 = Dense(24)(fusion_dense_0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_all = y_0\n",
    "    # Add()([y_0,\n",
    "    #            #y_1,y_2,y_3,y_4,y_5,y_6,y_7,y_8,y_9,y_10,y_11,y_12\n",
    "    #            ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出模型结构图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[x_input_use_0\n",
    "    #,x_input_use_1,x_input_use_2,x_input_use_3,x_input_use_4\n",
    "    # ,x_input_use_5,x_input_use_6,x_input_use_7,x_input_use_8,x_input_use_9,x_input_use_10,x_input_use_11,x_input_use_12\n",
    "                      ], outputs=y_all)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#在发现loss不再降低或者acc不再提高之后，降低学习率\n",
    "Reduce = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5,\n",
    "                           mode='auto', cooldown=0, min_lr=0.000001, verbose = 2)\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mean_absolute_error'\n",
    "             )\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='loss', patience=10, verbose=2),#当训练集上的loss不在减小（即减小的程度小于某个阈值）的时候停止继续训练。\n",
    "    ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True),#保存验证集准确率最高的模型\n",
    "    Reduce\n",
    "]\n",
    "print('\\nTrain')\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "history = model.fit(x = [train_data_use_0\n",
    "    #,train_data_use_1,train_data_use_2,train_data_use_3,train_data_use_4\n",
    "    # ,train_data_use_5,train_data_use_6,train_data_use_7,train_data_use_8,train_data_use_9,train_data_use_10,train_data_use_11,train_data_use_12\n",
    "                         ], y = train_label,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    shuffle=True,\n",
    "                    validation_data=([test_data_use_0\n",
    "                                         #,test_data_use_1,test_data_use_2,test_data_use_3,test_data_use_4\n",
    "                                         # ,test_data_use_5,test_data_use_6,test_data_use_7,test_data_use_8,test_data_use_9,test_data_use_10,test_data_use_11,test_data_use_12\n",
    "                                      ], test_label),\n",
    "                    callbacks=callbacks)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"\\nTraining process is end !\")\n",
    "print(training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面是模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "#加载保存的模型并预测测试集结果\n",
    "model = load_model(model_name)\n",
    "pre_fusion = model.predict([test_data_use_0\n",
    "                               #,test_data_use_1,test_data_use_2,test_data_use_3,test_data_use_4\n",
    "                               # ,test_data_use_5,test_data_use_6,test_data_use_7,test_data_use_8,test_data_use_9,test_data_use_10,test_data_use_11,test_data_use_12\n",
    "                            ])\n",
    "pre_fusion_ = pre_fusion.reshape(-1)\n",
    "test_label_ = test_label.reshape(-1)\n",
    "summ = 0\n",
    "for i in range(len(pre_fusion)):\n",
    "    summ+=np.abs((test_label_[i]-pre_fusion_[i])/test_label_[i])\n",
    "    \n",
    "mape = (summ/len(pre_fusion))\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "#加载保存的模型并预测测试集结果\n",
    "model = load_model(model_name)\n",
    "pre_fusion = model.predict([test_data_use_0\n",
    "                               #,test_data_use_1,test_data_use_2,test_data_use_3,test_data_use_4\n",
    "                               # ,test_data_use_5,test_data_use_6,test_data_use_7,test_data_use_8,test_data_use_9,test_data_use_10,test_data_use_11,test_data_use_12\n",
    "                            ])\n",
    "pre_fusion_ = pre_fusion.reshape(-1)\n",
    "test_label_ = test_label.reshape(-1)\n",
    "summ = 0\n",
    "for i in range(len(pre_fusion)):\n",
    "    summ+=np.abs(test_label_[i]-pre_fusion_[i])\n",
    "    \n",
    "mae = (summ/len(pre_fusion))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pre_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "predict = pre_fusion_\n",
    "actual = test_label_\n",
    "x = [x for x in range(24)]\n",
    "fig, ax = plt.subplots(figsize=(15,5),dpi = 300)\n",
    "ax.plot(x, predict, linewidth=2.0,label = \"predict\")\n",
    "ax.plot(x, actual, linewidth=2.0,label = \"actual\")\n",
    "ax.legend(loc=2);\n",
    "# ax.set_title(bf_name)\n",
    "plt.ylim((0, 1))\n",
    "plt.grid(linestyle='-.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面绘制了对应的混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False,\n",
    "                          title='Confusion matrix', figsize=(12,10),\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 1.5\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.xlabel('True label')\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "model = load_model(model_name)\n",
    "classes = ['0', '1', '2', '3', '4']\n",
    "plot_confusion_matrix(label_pre, label_test, classes, normalize=False,title='Confusion matrix', figsize=(4, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}